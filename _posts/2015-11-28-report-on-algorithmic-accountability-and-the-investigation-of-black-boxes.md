---
ID: 1273
post_title: 'Report: On Algorithmic Accountability and the Investigation of Black Boxes'
author: Michel Bauwens
post_date: 2015-11-28 03:58:05
post_excerpt: |
  <p>* Report: Nicholas Diakopoulos. Algorithmic Accountability: On the Investigation of Black Boxes. Knight Foundation and the Tow Center on Digital Journalism at Columbia Journalism School. Here is an introduction to the thematic of the report: &ldquo;The past three years have seen a small profusion of websites, perhaps as many as 80, spring up to capitalize [&hellip;]</p>
  <p>The post <a rel="nofollow" href="http://blog.p2pfoundation.net/report-on-algorithmic-accountability-and-the-investigation-of-black-boxes/2015/11/28">Report: On Algorithmic Accountability and the Investigation of Black Boxes</a> appeared first on <a rel="nofollow" href="http://blog.p2pfoundation.net/">P2P Foundation</a>.</p>
layout: post
permalink: >
  http://flolab.org/wp3/2015/11/28/report-on-algorithmic-accountability-and-the-investigation-of-black-boxes/
published: true
enclosure:
  - |
    |
        
        
        
syndication_source:
  - P2P Foundation
syndication_source_uri:
  - http://blog.p2pfoundation.net
syndication_source_id:
  - >
    http://feeds.feedburner.com/P2pFoundation
"wfw:commentRSS":
  - >
    http://blog.p2pfoundation.net/report-on-algorithmic-accountability-and-the-investigation-of-black-boxes/2015/11/28/feed
syndication_feed:
  - >
    http://feeds.feedburner.com/P2pFoundation
syndication_feed_id:
  - "2"
syndication_permalink:
  - >
    http://feedproxy.google.com/~r/P2pFoundation/~3/HIj-QkEC4Jk/28
syndication_item_hash:
  - afc3dc7feedb89bd91d3bd6f3dbf4357
---
*** Report: Nicholas Diakopoulos. [Algorithmic Accountability][1]: On the Investigation of Black Boxes. Knight Foundation and the Tow Center on Digital Journalism at Columbia Journalism School.**

Here is an *introduction* to the thematic of the report:

“The past three years have seen a small profusion of websites, perhaps as many as 80, spring up to capitalize on the high interest that mug shot photos generate online. Mug shots are public record, artifacts of an arrest, and these websites collect, organize, and optimize the photos so that they’re found more easily online. Proponents of such sites argue that the public has a right to know if their neighbor, romantic date, or colleague has an arrest record. Still, mug shots are not proof of conviction; they don’t signal guilt. Having one online is likely to result in a reputational blemish; having that photo ranked as the first result when someone searches for your name on Google turns that blemish into a garish reputational wound, festering in facile accessibility. Some of these websites are exploiting this, charging people to remove their photo from the site so that it doesn’t appear in online searches.

It’s reputational blackmail. And remember, these people aren’t necessarily guilty of anything. To crack down on the practice, states like Oregon, Georgia, and Utah have passed laws requiring these sites to take down the photos if the person’s record has been cleared. Some credit card companies have stopped processing payments for the seediest of the sites. Clearly both legal and market forces can help curtail this activity, but there’s another way to deal with the issue too: algorithms. Indeed, Google recently launched updates to its ranking algorithm that down-weight results from mug shot websites, basically treating them more as spam than as legitimate information sources. With a single knock of the algorithmic gavel, Google declared such sites illegitimate. At the turn of the millennium, 14 years ago, Lawrence Lessig taught us that “code is law”—that the architecture of systems, and the code and algorithms that run them, can be powerful influences on liberty. We’re living in a world now where algorithms adjudicate more and more consequential decisions in our lives. It’s not just search engines either; it’s everything from online review systems to educational evaluations, the operation of markets to how political campaigns are run, and even how social services like welfare and public safety are managed. Algorithms, driven by vast troves of data, are the new power brokers in society. As the mug shots example suggests, algorithmic power isn’t necessarily detrimental to people; it can also act as a positive force. The intent here is not to demonize algorithms, but to recognize that they operate with biases like the rest of us. And they can make mistakes. What we generally lack as a public is clarity about how algorithms exercise their power over us. With that clarity comes an increased ability to publicly debate and dialogue the merits of any particular algorithmic power. While legal codes are available for us to read, algorithmic codes are more opaque, hidden behind layers of technical complexity. How can we characterize the power that various algorithms may exert on us? And how can we better understand when algorithms might be wronging us? What should be the role of journalists in holding that power to account? In the next section I discuss what algorithms are and how they encode power. I then describe the idea of algorithmic accountability, first examining how algorithms problematize and sometimes stand in tension with transparency. Next, I describe how reverse engineering can provide an alternative way to characterize algorithmic power by delineating a conceptual model that captures different investigative scenarios based on reverse engineering algorithms’ input-output relationships. I then provide a number of illustrative cases and methodological details on how algorithmic accountability reporting might be realized in practice. I conclude with a discussion about broader issues of human resources, legality, ethics, and transparency.”

**Nicholas Diakopoulos also explains Algorithmic Power:**

“An algorithm can be defined as a series of steps undertaken in order to solve a particular problem or accomplish a defined outcome. Algorithms can be carried out by people, by nature, or by machines. The way you learned to do long division in grade school or the recipe you followed last night to cook dinner are examples of people executing algorithms. You might also say that biologically governed algorithms describe how cells transcribe DNA to RNA and then produce proteins—it’s an information transformation process. While algorithms are everywhere around us, the focus of this paper are those algorithms that run on digital computers, since they have the most potential to scale and affect large swaths of people. Autonomous decision-making is the crux of algorithmic power. Algorithmic decisions can be based on rules about what should happen next in a process, given what’s already happened, or on calculations over massive amounts of data. The rules themselves can be articulated directly by programmers, or be dynamic and flexible based on the data. For instance, machine-learning algorithms enable other algorithms to make smarter decisions based on learned patterns in data. Sometimes, though, the outcomes are important (or messy and uncertain) enough that a human operator makes the final decision in a process. But even in this case the algorithm is biasing the operator, by directing his or her attention to a subset of information or recommended decision. Not all of these decisions are significant of course, but some of them certainly can be. We can start to assess algorithmic power by thinking about the atomic decisions that algorithms make, including prioritization, classification, association, and filtering.

Sometimes these decisions are chained in order to form higher-level decisions and information transformations. For instance, some set of objects might be classified and then subsequently ranked based on their classifications. Or, certain associations to an object could help classify it: Two eyes and a nose associated with a circular blob might help you determine the blob is actually a face. Another composite decision is summarization, which uses prioritization and then filtering operations to consolidate information while maintaining the interpretability of that information. Understanding the elemental decisions that algorithms make, including the compositions of those decisions, can help identify why a particular algorithm might warrant further investigation.” 

<a class="a2a_button_facebook" href="http://www.addtoany.com/add_to/facebook?linkurl=http%3A%2F%2Fblog.p2pfoundation.net%2Freport-on-algorithmic-accountability-and-the-investigation-of-black-boxes%2F2015%2F11%2F28&linkname=Report%3A%20On%20Algorithmic%20Accountability%20and%20the%20Investigation%20of%20Black%20Boxes" title="Facebook" rel="nofollow"><img src="http://blog.p2pfoundation.net/wp-content/plugins/add-to-any/icons/facebook.png" width="16" height="16" alt="Facebook" /></a><a class="a2a_button_twitter" href="http://www.addtoany.com/add_to/twitter?linkurl=http%3A%2F%2Fblog.p2pfoundation.net%2Freport-on-algorithmic-accountability-and-the-investigation-of-black-boxes%2F2015%2F11%2F28&linkname=Report%3A%20On%20Algorithmic%20Accountability%20and%20the%20Investigation%20of%20Black%20Boxes" title="Twitter" rel="nofollow"><img src="http://blog.p2pfoundation.net/wp-content/plugins/add-to-any/icons/twitter.png" width="16" height="16" alt="Twitter" /></a><a class="a2a_button_google_plus" href="http://www.addtoany.com/add_to/google_plus?linkurl=http%3A%2F%2Fblog.p2pfoundation.net%2Freport-on-algorithmic-accountability-and-the-investigation-of-black-boxes%2F2015%2F11%2F28&linkname=Report%3A%20On%20Algorithmic%20Accountability%20and%20the%20Investigation%20of%20Black%20Boxes" title="Google+" rel="nofollow"><img src="http://blog.p2pfoundation.net/wp-content/plugins/add-to-any/icons/google_plus.png" width="16" height="16" alt="Google+" /></a><a class="a2a_button_reddit" href="http://www.addtoany.com/add_to/reddit?linkurl=http%3A%2F%2Fblog.p2pfoundation.net%2Freport-on-algorithmic-accountability-and-the-investigation-of-black-boxes%2F2015%2F11%2F28&linkname=Report%3A%20On%20Algorithmic%20Accountability%20and%20the%20Investigation%20of%20Black%20Boxes" title="Reddit" rel="nofollow"><img src="http://blog.p2pfoundation.net/wp-content/plugins/add-to-any/icons/reddit.png" width="16" height="16" alt="Reddit" /></a><a class="a2a_dd a2a_target addtoany_share_save" href="https://www.addtoany.com/share#url=http%3A%2F%2Fblog.p2pfoundation.net%2Freport-on-algorithmic-accountability-and-the-investigation-of-black-boxes%2F2015%2F11%2F28&title=Report%3A%20On%20Algorithmic%20Accountability%20and%20the%20Investigation%20of%20Black%20Boxes" id="wpa2a_2"><img src="http://blog.p2pfoundation.net/wp-content/plugins/add-to-any/share_save_120_16.png" width="120" height="16" alt="Share" /></a>

The post <a rel="nofollow" href="http://blog.p2pfoundation.net/report-on-algorithmic-accountability-and-the-investigation-of-black-boxes/2015/11/28">Report: On Algorithmic Accountability and the Investigation of Black Boxes</a> appeared first on <a rel="nofollow" href="http://blog.p2pfoundation.net/">P2P Foundation</a>.

<div class="feedflare">
  <a href="http://feeds.feedburner.com/~ff/P2pFoundation?a=HIj-QkEC4Jk:xMj4E6nBUs8:7Q72WNTAKBA"><img src="http://feeds.feedburner.com/~ff/P2pFoundation?d=7Q72WNTAKBA" border="0" /></img></a> <a href="http://feeds.feedburner.com/~ff/P2pFoundation?a=HIj-QkEC4Jk:xMj4E6nBUs8:D7DqB2pKExk"><img src="http://feeds.feedburner.com/~ff/P2pFoundation?i=HIj-QkEC4Jk:xMj4E6nBUs8:D7DqB2pKExk" border="0" /></img></a> <a href="http://feeds.feedburner.com/~ff/P2pFoundation?a=HIj-QkEC4Jk:xMj4E6nBUs8:2mJPEYqXBVI"><img src="http://feeds.feedburner.com/~ff/P2pFoundation?d=2mJPEYqXBVI" border="0" /></img></a>
</div>

<img src="http://feeds.feedburner.com/~r/P2pFoundation/~4/HIj-QkEC4Jk" height="1" width="1" alt="" />

 [1]: http://towcenter.org/research/algorithmic-accountability-on-the-investigation-of-black-boxes-2/